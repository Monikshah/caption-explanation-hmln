{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ea738f-330e-4c31-ad2e-40e0f0287c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NEW processing for GT test set \n",
    "import nltk\n",
    "import json\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "formulamapfile = \"formulaimgmap.json\"\n",
    "with open(formulamapfile, 'r') as file:\n",
    "    formulaimgmap = json.load(file)\n",
    "\n",
    "\n",
    "# extripclipfile = \"allTripClipScore/extractedTripXlan.json\"\n",
    "# with open(extripclipfile, 'r') as file:\n",
    "    # extripclipscores = json.load(file)\n",
    "\n",
    "# modelname = 'xlan'\n",
    "# dirname = \"output_test_\"+modelname+\"/\"\n",
    "# files = os.listdir(dirname)\n",
    "modelname = 'GT'\n",
    "C1 = 0\n",
    "C2=0\n",
    "C3=0\n",
    "grcounts = []\n",
    "doneprocessing = {}\n",
    "groundingmap = defaultdict(list)\n",
    "captionmap = {}\n",
    "img2triples = defaultdict(list)\n",
    "testrel2formclips = defaultdict(list)\n",
    "\n",
    "with open('allTripletsGT_Test.json', 'r') as file:\n",
    "    img2triplesGT = json.load(file)\n",
    "    \n",
    "with open('captionGenTest/test_gt_caption.json') as file:\n",
    "    allcaptionGT = json.load(file)\n",
    "# for filename in files:\n",
    "#     if filename.find(\".ipynb_checkpoints\")>=0:\n",
    "#         continue\n",
    "#     separator = \"Caption\"\n",
    "#     if not os.path.isfile(dirname+filename):\n",
    "#         continue\n",
    "#     C3=C3+1\n",
    "#     #if C3>1:\n",
    "#     #    break\n",
    "#     ifile = open(dirname+filename)\n",
    "#     alltriplets = []\n",
    "#     allcaptions = []\n",
    "#     imageids = []\n",
    "#     testrel2formclips = defaultdict(list)\n",
    "#     for ln in ifile:\n",
    "#         if ln.find(separator)==0:\n",
    "#             cparts = ln.strip().split(\":\")\n",
    "#             incap = {}\n",
    "#             ln1 = ifile.readline()\n",
    "#             p1 = ln1.find(\"Imageid: \")\n",
    "#             p2 = ln1.find(\",\")\n",
    "#             parts = ln1[p1:p2].split(\":\")\n",
    "#             if len(parts) < 2:\n",
    "#                 continue\n",
    "#             imageid = parts[1].strip()\n",
    "#             if str(imageid) in doneprocessing:\n",
    "#                 continue\n",
    "#             p1 = ln1.find(\"extracted triplets: [\")\n",
    "#             p2 = ln1.find(\"]\")\n",
    "#             parts = ln1[p1:p2].split(\"[\")\n",
    "#             if len(parts)<2:\n",
    "#                 continue\n",
    "#             extr = parts[1].split(\",\")\n",
    "#need to start from here\n",
    "for imageid in img2triplesGT:\n",
    "    extr = img2triplesGT[imageid]\n",
    "    cparts = allcaptionGT[imageid] #taking first caption\n",
    "    # for i in range(0,len(extr),1):\n",
    "        # extr[i] = extr[i].strip()\n",
    "        # extr[i] = extr[i][1:len(extr[i])-1]\n",
    "\n",
    "    if imageid in img2triples:\n",
    "        continue\n",
    "    for e1 in extr:\n",
    "        img2triples[imageid].append(e1)\n",
    "    pairs = []\n",
    "    pairclipscores = {}\n",
    "    newobjs = []\n",
    "    if len(extr)==1:\n",
    "        #C1 = C1+1\n",
    "        tokens = nltk.word_tokenize(cparts[0])\n",
    "        tagged = nltk.pos_tag(tokens)\n",
    "        sparts = extr[0].split()\n",
    "        for tg in tagged:\n",
    "            if tg[1]=='NN':\n",
    "                if tg[0]!=sparts[0] and tg[0]!=sparts[len(sparts)-1]:\n",
    "                    newobjs.append(tg[0])\n",
    "        #if len(newobjs)==0:\n",
    "        #    C1=C1+1\n",
    "        P1 = extr[0].split()\n",
    "        pairs.append(P1[0])\n",
    "        pairs.append(P1[len(P1)-1])\n",
    "        #pairclipscores[P1[0]+\":\"+P1[len(P1)-1]] = clipscorestripls[extr[0]]\n",
    "    elif len(extr)==2:\n",
    "        #C2=C2+1\n",
    "        P1 = extr[0].split()\n",
    "        P2 = extr[1].split()\n",
    "        pairs.append(P1[0])\n",
    "        pairs.append(P1[len(P1)-1])\n",
    "        pairs.append(P2[0])\n",
    "        pairs.append(P2[len(P2)-1])\n",
    "        #pairclipscores[P1[0]+\":\"+P1[len(P1)-1]] = clipscorestripls[extr[0]]\n",
    "        #pairclipscores[P2[0]+\":\"+P2[len(P2)-1]] = clipscorestripls[extr[1]]\n",
    "    else:\n",
    "        #ofile.write(str(imageid)+\":\"+cparts[1]+\":\"+\",\".join(extr)+\"\\n\")\n",
    "        modtriples = []\n",
    "        for e in extr:\n",
    "            parts=e.split()\n",
    "            captionwords = cparts[0].split()\n",
    "            w1=False\n",
    "            w2=False\n",
    "            for c in captionwords:\n",
    "                if parts[0]==c:\n",
    "                    w1=True\n",
    "                if parts[len(parts)-1]==c:\n",
    "                    w2=True\n",
    "            if w1 and w2:\n",
    "                modtriples.append(e)\n",
    "\n",
    "        if len(modtriples)==0:\n",
    "            #C1=C1+1\n",
    "            tokens = nltk.word_tokenize(cparts[0])\n",
    "            tagged = nltk.pos_tag(tokens)\n",
    "            newobjs = []\n",
    "            for tg in tagged:\n",
    "                if tg[1]=='NN':\n",
    "                    newobjs.append(tg[0])\n",
    "        if len(modtriples)>=2:\n",
    "            for m in modtriples:\n",
    "                P1 = m.split()\n",
    "                pairs.append(P1[0])\n",
    "                pairs.append(P1[len(P1)-1])\n",
    "\n",
    "    cnt=0\n",
    "    newobjs = list(set(newobjs))\n",
    "    listofforms = []\n",
    "    for fr in formulaimgmap:\n",
    "        parts = fr.split(\":\")\n",
    "        gr = 0\n",
    "        P1 = parts[0].split()\n",
    "        P2 = parts[1].split()\n",
    "\n",
    "        tmp = []\n",
    "        tmp.append(P1[0])\n",
    "        tmp.append(P1[len(P1)-1])\n",
    "        tmp.append(P2[0])\n",
    "        tmp.append(P2[len(P2)-1])\n",
    "        if len(set(tmp))<3:\n",
    "            continue\n",
    "\n",
    "        m1 = False\n",
    "        m2 = False\n",
    "\n",
    "        for i in range(0,len(pairs)-1,2):\n",
    "            if P1[0]==pairs[i] and P1[len(P1)-1]==pairs[i+1]:\n",
    "                m1 = True\n",
    "                break\n",
    "        for i in range(0,len(pairs)-1,2):\n",
    "            if P2[0]==pairs[i] and P2[len(P2)-1]==pairs[i+1]:\n",
    "                m2 = True\n",
    "                break\n",
    "        if m1 and m2:\n",
    "            #testrel2formclips[fr].append(pairclipscores[P1[0]+\":\"+P1[len(P1)-1]])\n",
    "            #testrel2formclips[fr].append(pairclipscores[P2[0]+\":\"+P2[len(P2)-1]])\n",
    "            cnt=cnt+1\n",
    "            listofforms.append(fr)\n",
    "        else:\n",
    "            if m1 and ((P2[0] in newobjs) and (P2[len(P2)-1] in newobjs)):\n",
    "                cnt=cnt+1\n",
    "                #testrel2formclips[fr].append(pairclipscores[P1[0]+\":\"+P1[len(P1)-1]])\n",
    "                #testrel2formclips[fr].append(0)\n",
    "                listofforms.append(fr)\n",
    "            if m2 and ((P1[0] in newobjs) and (P1[len(P1)-1] in newobjs)):\n",
    "                cnt=cnt+1\n",
    "                #testrel2formclips[fr].append(0)\n",
    "                #testrel2formclips[fr].append(pairclipscores[P2[0]+\":\"+P2[len(P2)-1]])\n",
    "                listofforms.append(fr)\n",
    "\n",
    "    groundingmap[str(imageid)]=listofforms\n",
    "    #grcounts.append(cnt)\n",
    "    doneprocessing[str(imageid)]=1     \n",
    "    captionmap[str(imageid)]=cparts[0]\n",
    "    # ifile.close()\n",
    "with open('groundingmap-{}.json'.format(modelname), 'w') as fp:\n",
    "    json.dump(groundingmap, fp) \n",
    "with open('captionmap-{}.json'.format(modelname), 'w') as fp:\n",
    "    json.dump(captionmap, fp) \n",
    "# with open('testrel2formsclip-{}.json'.format(modelname), 'w') as fp:\n",
    "   # json.dump(testrel2formclips, fp) \n",
    "with open('img2trip-{}.json'.format(modelname), 'w') as fp:\n",
    "   json.dump(img2triples, fp) "
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m113",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m113"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
